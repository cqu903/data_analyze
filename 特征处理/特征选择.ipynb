{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择\n",
    "当数据特征维度过大，则在传统机器学习中需要选择有效的特征进行训练，主要介绍特征选择的方式方法\n",
    "### 过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./digit recognizor.csv')\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      41151\n",
       "253       53\n",
       "254       38\n",
       "255       16\n",
       "5         15\n",
       "252       13\n",
       "7         13\n",
       "128       12\n",
       "3         10\n",
       "1         10\n",
       "32         9\n",
       "64         9\n",
       "2          8\n",
       "4          8\n",
       "14         8\n",
       "22         8\n",
       "28         8\n",
       "47         8\n",
       "86         7\n",
       "13         7\n",
       "203        7\n",
       "9          7\n",
       "101        7\n",
       "24         7\n",
       "8          7\n",
       "55         7\n",
       "80         7\n",
       "25         7\n",
       "51         7\n",
       "57         6\n",
       "       ...  \n",
       "187        1\n",
       "78         1\n",
       "213        1\n",
       "75         1\n",
       "42         1\n",
       "246        1\n",
       "181        1\n",
       "235        1\n",
       "119        1\n",
       "180        1\n",
       "116        1\n",
       "140        1\n",
       "120        1\n",
       "152        1\n",
       "184        1\n",
       "216        1\n",
       "89         1\n",
       "135        1\n",
       "52         1\n",
       "217        1\n",
       "166        1\n",
       "243        1\n",
       "211        1\n",
       "173        1\n",
       "186        1\n",
       "205        1\n",
       "147        1\n",
       "170        1\n",
       "59         1\n",
       "176        1\n",
       "Name: pixel200, Length: 219, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['pixel200'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果某些特征的方差很小。则说明该特征基本没有差异，则对于目标的变化影响也较小，因此可以先用方差进行过滤，将特征差异小的值删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 708)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#方差过滤\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0)\n",
    "x_var0 = selector.fit_transform(X)\n",
    "x_var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 392)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#删除一半的方差值\n",
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)\n",
    "X.var().values\n",
    "np.median(X.var().values)\n",
    "X_fsvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380003861799541\n",
      "0.9388098166696807\n"
     ]
    }
   ],
   "source": [
    "#对于随机森林模型的方差过滤前后表现\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(cross_val_score(RandomForestClassifier(random_state=0,n_estimators=10),X,y,cv=5).mean())\n",
    "print(cross_val_score(RandomForestClassifier(random_state=0,n_estimators=10),X_fsvar,y,cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 讨论：方差过滤对于随机森林和knn的影响分析以及随机森林和决策树在维度选择中的表现分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关性过滤\n",
    "如何选出与标签相关且有意义的特征，因为这样的特征能够为我们提供大量信息。如果特征与标签无关，不会带来表现提升，反而还会给模型带来噪音。在sklearn有三种常用的方法来评判特征与标签之间的相关性:卡方，F检验，互信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卡方检验\n",
    "卡方过滤是专门针对离散型标签(即分类问题)的相关性过滤。卡方检验类feature_selection.chi2计算每个非负特征和标签之间的卡方统计量，并依照卡方统计量由高到低为特征排名。再结合feature_selection.SelectKBest 这个可以输入”评分标准“来选出前K个分数最高的特征的类，可以借此除去最可能独立于标签，与分类目的无关的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#卡方检验\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "X_fschi = SelectKBest(chi2,k=300).fit_transform(X_fsvar,y)\n",
    "X_fschi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333098667649198"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#如何确定合适的k\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "score = []\n",
    "for i in range(350,200,-10):\n",
    "    X_fschi = SelectKBest(chi2, k=i).fit_transform(X_fsvar, y)\n",
    "    once = cross_val_score(RandomForestClassifier(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.plot(range(350,200,-10),score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运用P值检测\n",
    "卡方检验的本质是推测两组数据之间的差异，其检验的原假设是”两组数据是相互独立的”。卡方检验返回卡方值和P值两个统计量，其中卡方值很难界定有效的范围，而p值，一般使用0.01或0.05作为显著性水平，即p值判断的边界  \n",
    "\n",
    "P|小于阈值|大于阈值\n",
    "--|:--:|--:\n",
    "数据差异|差异不是自然形成|差异是自然的样本误差\n",
    "相关性|两组数据相关|两组数据相互独立\n",
    "原假设|拒绝原假设，接受备择假设|接受原假设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chivalue, pvalues_chi = chi2(X_fsvar,y)\n",
    "pvalues_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chivalue.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = chivalue.shape[0] - (pvalues_chi > 0.05).sum()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388098166696807"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fschi = SelectKBest(chi2, k=k).fit_transform(X_fsvar, y)\n",
    "cross_val_score(RandomForestClassifier(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F检验\n",
    "F检验，又称ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法。它即可以做回归也可以做分类，因此包含feature_selection.f_classif(F检验分类)和feature_selection.f_regression(F检验回归)两个类。其中F检验分类用于标签是离散型变量的数据，而F检验回归用于标签是连续型变量的数据。\n",
    "\n",
    "F检验在数据服从正态分布时效果会非常稳定，因此如果使用F检验过滤，需要先将数据转换成服从正态分布的方式。\n",
    "\n",
    "F检验的本质是寻找两组数据之间的线性关系，其原假设是”数据不存在显著的线性关系“。它返回F值和p值两个统计量。\n",
    "\n",
    "思考： why正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 618.65383492,  846.18897012, 1115.40617051, 1362.3677305 ,\n",
       "       1452.03355369, 1381.09095571, 1138.26505266,  464.29616121,\n",
       "        660.00977785,  849.66393412, 1004.7450309 , 1124.76177588,\n",
       "       1200.99190762, 1209.29489877, 1110.4944286 ,  854.66183292,\n",
       "        577.52063451,  342.09729054,  178.67397866,  118.01145533,\n",
       "        612.12261014,  899.40904291, 1196.17528948, 1424.49864852,\n",
       "       1569.26556677, 1742.49910702, 1910.98023795, 1969.20520223,\n",
       "       1731.37475948, 1295.09668012,  839.15325001,  531.97951763,\n",
       "        371.82392681,  336.00820537,  378.93378743,  317.47025479,\n",
       "        528.94881012,  766.40792176,  947.63168717, 1086.0472161 ,\n",
       "       1177.72017709, 1253.79641973, 1344.06961068, 1507.33781169,\n",
       "       1616.50454434, 1512.25864876, 1289.65180587, 1051.26276412,\n",
       "        839.48869386,  680.07426932,  600.85538567,  633.55772663,\n",
       "        683.96908509,  347.65867784,  452.76238211,  509.16387684,\n",
       "        515.7498157 ,  532.86107778,  594.62512658,  664.18740444,\n",
       "        709.37133696,  798.11767931,  876.69849088,  852.76926441,\n",
       "        785.70173347,  802.88980095,  813.2041131 ,  760.85552527,\n",
       "        687.94148028,  642.84071735,  698.11530217,  367.16414289,\n",
       "        455.90449427,  485.50500277,  476.23046034,  536.72332365,\n",
       "        740.12587382, 1041.38089649, 1168.8028973 ,  941.91083922,\n",
       "        795.72843454,  861.29818828,  868.19464432,  838.80173567,\n",
       "        886.26659655,  959.12740961,  934.56890789,  783.1988476 ,\n",
       "        631.01107034,  542.02937189,  493.83337615,  533.27899195,\n",
       "        572.34131749,  657.20547321,  981.66873526, 1465.82267956,\n",
       "       1756.05831022, 1385.28086085,  798.73125604,  761.40508874,\n",
       "       1062.6919609 ,  979.38193965,  947.82602644, 1085.00522683,\n",
       "       1152.13801689, 1118.1595422 , 1021.13086631,  812.37823266,\n",
       "        509.86857625,  411.37986706,  430.7150329 ,  545.55866945,\n",
       "        829.92259533, 1376.4852629 , 1811.62922878, 1601.33613631,\n",
       "        898.8719158 ,  417.37765921,  895.77244253, 1455.38592931,\n",
       "        956.2421521 ,  990.1748413 , 1359.47406197, 1279.27992017,\n",
       "       1166.80888121, 1291.41792351, 1263.86987819,  787.81807986,\n",
       "        237.21811742,  333.12552194,  621.47324186, 1139.04489426,\n",
       "       1713.54508435, 1823.42451065, 1436.53069242,  884.19442779,\n",
       "        717.63373994, 2026.90370414, 2219.46450157,  943.55587655,\n",
       "       1217.29127813, 1677.03878308, 1193.63540136, 1039.56842784,\n",
       "       1570.18098323, 1878.5600272 , 1284.78903715,  190.02740438,\n",
       "        444.17019739,  928.80156872, 1562.54171587, 1940.54801063,\n",
       "       1816.57346013, 1683.83193784, 1619.17496376, 1865.78706551,\n",
       "       3482.82350415, 2326.10253286,  990.67999393, 1632.46650414,\n",
       "       1652.51500198,  891.26746579,  883.96689508, 1805.57103626,\n",
       "       2389.97435433, 1630.34926872,  301.84091297,  746.3286491 ,\n",
       "       1394.82469151, 2008.19411716, 2107.3680475 , 1767.97892382,\n",
       "       1786.08753011, 1980.1986791 , 2509.14739387, 3366.13986444,\n",
       "       1959.90573326, 1299.36608875, 2218.28123025, 1470.25657381,\n",
       "        681.02610086,  937.54741741, 2037.45812231, 2518.68810085,\n",
       "       1583.0009463 ,  509.76276636, 1139.21364745, 1881.71834116,\n",
       "       2351.30851824, 2175.48525458, 1624.49647062, 1399.44534221,\n",
       "       1440.98664744, 2229.25720739, 2764.00452882, 1633.74258116,\n",
       "       1870.29253742, 2628.79930504, 1367.31440177,  707.38857243,\n",
       "       1150.06936228, 2089.08213594, 2185.00557858, 1318.14722036,\n",
       "        747.37697661, 1453.94015412, 2116.40726513, 2399.53090598,\n",
       "       2143.53519978, 1651.89817908, 1414.71662551, 1481.62100314,\n",
       "       2468.21266727, 2666.18025642, 1520.6400065 , 2223.14029953,\n",
       "       2271.07109628, 1111.06997494,  844.31183874, 1388.60413626,\n",
       "       1917.10207189, 1667.61400215,  996.09054823,  907.80926355,\n",
       "       1607.70263546, 2085.21461056, 2073.68356276, 1880.26929744,\n",
       "       1756.40165025, 1716.45478479, 1964.08537105, 2796.13761562,\n",
       "       2413.09378391, 1543.01310963, 2118.10377396, 1475.29541488,\n",
       "        783.59003763, 1040.65400476, 1582.46200024, 1617.32566033,\n",
       "       1188.24554305,  642.2665701 , 1011.30241064, 1725.70185142,\n",
       "       2067.20755476, 1893.35116837, 1795.96538455, 1922.58627318,\n",
       "       1951.69309645, 2115.44871238, 2479.27958039, 1809.12095649,\n",
       "       1330.8686207 , 1396.29767244,  741.9063402 ,  751.14036409,\n",
       "       1410.18529816, 1677.6595494 , 1308.77910167,  836.77047561,\n",
       "        430.93133677,  313.888671  , 1039.31894918, 1811.68171256,\n",
       "       2191.69964967, 2035.63638826, 2114.65218363, 2511.27142071,\n",
       "       2363.46743373, 2053.7687027 , 1865.84769096, 1202.94179711,\n",
       "        793.61414555,  633.71267282,  636.18282736, 1218.61245591,\n",
       "       1712.62901816, 1484.60290068,  996.06129466,  626.13659134,\n",
       "        441.56356583,  374.08815796,  983.21640593, 1764.93014215,\n",
       "       2264.93587233, 2262.87269162, 2323.50890468, 2611.66920897,\n",
       "       2387.45723028, 1763.5696083 , 1256.32165954,  704.77285945,\n",
       "        406.94580935,  548.06969664, 1051.50016486, 1542.11172909,\n",
       "       1494.38472469, 1130.61174365,  823.84437277,  650.69506052,\n",
       "        594.18011033,  415.73313115,  853.97575783, 1548.7167469 ,\n",
       "       2204.00694989, 2444.69535795, 2267.62871155, 2003.69161124,\n",
       "       1643.94961527, 1202.35520102,  804.18805494,  483.32932365,\n",
       "        420.99263006,  750.06949525, 1136.32227345, 1202.49476981,\n",
       "        990.75097727,  791.03016258,  692.46641159,  653.96372577,\n",
       "        647.90433225, 1149.80460733, 1826.54973661, 2361.75564926,\n",
       "       2313.09139096, 1694.26613916, 1012.97938867,  608.4174945 ,\n",
       "        432.07115684,  383.54620406,  487.70312805,  698.78061024,\n",
       "        797.0763827 ,  714.70722998,  574.2849126 ,  507.5143557 ,\n",
       "        508.77434021,  510.36884435,  404.13860698,  686.31274396,\n",
       "       1103.81003251, 1590.83695172, 1912.74984902, 1832.62220523,\n",
       "       1482.39046946, 1142.10827805,  968.65089356,  860.24853405,\n",
       "        780.75215696,  696.78170045,  567.41403081,  403.59649375,\n",
       "        284.91007929,  245.59060983,  255.97458001,  293.6787996 ,\n",
       "        460.46868009,  687.29383613,  940.06512113, 1205.58777055,\n",
       "       1485.37178744, 1623.12886955, 1488.04856361, 1119.91615126,\n",
       "        770.06544455,  530.6398126 ,  376.66549502,  258.05875548,\n",
       "        172.20323661,  123.79865884,  160.44132806,  249.15104257,\n",
       "        374.15221131,  544.73535425,  727.78945347,  853.98680046,\n",
       "        819.19801306,  656.55547718,  510.87851723,  445.09613969,\n",
       "        401.25608847,  333.48574029,  243.88699402,  645.9545719 ,\n",
       "        920.3259526 , 1196.07900013, 1308.12260763, 1218.37705687,\n",
       "        996.41501921,  792.59409228,  663.47516843,  550.14745143])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "F,pvalues_f = f_classif(X_fsvar,y)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 4.71193533e-220,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       3.26083326e-322, 5.24336441e-231, 4.04009647e-300, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "       0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalues_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = F.shape[0] - (pvalues_f > 0.05).sum()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388098166696807"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsF = SelectKBest(f_classif, k=k).fit_transform(X_fsvar, y)\n",
    "cross_val_score(RandomForestClassifier(n_estimators=10,random_state=0),X_fsF,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 互信息法\n",
    "互信息法是用来捕捉每个特征与标签之间的任意关系(包括线性和非线性关系)的过滤方法。和F检验相似，它既可以做回归也可以做分类，并且包含两个类feature_selection.mutual_info_classif(互信息分类)和 feature_selection.mutual_info_regression(互信息回归)。这两个类的用法和参数都和F检验一模一样，不过 互信息法比F检验更加强大，F检验只能够找出线性关系，而互信息法可以找出任意关系。\n",
    "\n",
    "互信息法不返回p值或F值类似的统计量，它返回“每个特征与目标之间的互信息量的估计”，这个估计量在[0,1]之间 取值，为0则表示两个变量独立，为1则表示两个变量完全相关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06993631, 0.08330239, 0.10259283, 0.1152163 , 0.11718048,\n",
       "       0.10566585, 0.08147838, 0.05144574, 0.07419917, 0.10241877,\n",
       "       0.12110731, 0.13760926, 0.16079681, 0.16586878, 0.14513028,\n",
       "       0.12686926, 0.09553066, 0.05819486, 0.04211889, 0.02063632,\n",
       "       0.0682048 , 0.09364586, 0.12273829, 0.15674711, 0.17679987,\n",
       "       0.20676681, 0.22453458, 0.23732893, 0.21765135, 0.17817215,\n",
       "       0.14194711, 0.10342029, 0.06859084, 0.0560314 , 0.04624681,\n",
       "       0.03310984, 0.05280198, 0.07899737, 0.10309685, 0.11922619,\n",
       "       0.13670738, 0.15157465, 0.16513443, 0.18132124, 0.18819832,\n",
       "       0.17392391, 0.15433643, 0.13706864, 0.10541003, 0.09469067,\n",
       "       0.08366965, 0.06726403, 0.06700389, 0.04645883, 0.06470149,\n",
       "       0.07571494, 0.08888498, 0.10006336, 0.10434652, 0.10523933,\n",
       "       0.10873541, 0.11641621, 0.12639178, 0.11905236, 0.11122131,\n",
       "       0.11636676, 0.11160015, 0.10965565, 0.08798357, 0.08489494,\n",
       "       0.07058252, 0.03614557, 0.05042659, 0.0683539 , 0.07314482,\n",
       "       0.096947  , 0.11996277, 0.14752556, 0.13871907, 0.1250043 ,\n",
       "       0.10416778, 0.11460653, 0.11493944, 0.11511979, 0.12397693,\n",
       "       0.14204484, 0.12739832, 0.10787512, 0.08368151, 0.0749127 ,\n",
       "       0.04559105, 0.05743609, 0.06295657, 0.09281273, 0.14163991,\n",
       "       0.18566255, 0.1979719 , 0.15694199, 0.10626466, 0.09869809,\n",
       "       0.13078818, 0.12380808, 0.13328416, 0.14473016, 0.14990446,\n",
       "       0.13713936, 0.12029531, 0.0922222 , 0.05856273, 0.03987434,\n",
       "       0.05291722, 0.08012283, 0.11530127, 0.18270405, 0.22169339,\n",
       "       0.19018087, 0.12379296, 0.07257075, 0.10133264, 0.14606903,\n",
       "       0.12353374, 0.12880571, 0.16277344, 0.15934021, 0.14424725,\n",
       "       0.12488101, 0.10896102, 0.06897013, 0.03291099, 0.05291745,\n",
       "       0.10110156, 0.15242643, 0.21447673, 0.20910621, 0.17608788,\n",
       "       0.1226717 , 0.10845002, 0.17907802, 0.19303437, 0.12352107,\n",
       "       0.15138864, 0.18535704, 0.15166608, 0.1316971 , 0.13710563,\n",
       "       0.12752459, 0.08303095, 0.0332587 , 0.0698776 , 0.13189842,\n",
       "       0.18671488, 0.22440367, 0.22409488, 0.20059514, 0.16851113,\n",
       "       0.18887179, 0.25941634, 0.21975232, 0.14381931, 0.18156517,\n",
       "       0.18394745, 0.13737644, 0.13128081, 0.14380271, 0.1356237 ,\n",
       "       0.09815296, 0.03167798, 0.08840236, 0.15239112, 0.21683723,\n",
       "       0.22897299, 0.21255508, 0.19826567, 0.20081553, 0.25188772,\n",
       "       0.29103424, 0.21426029, 0.17333271, 0.22384781, 0.18453214,\n",
       "       0.12018047, 0.1185012 , 0.15262607, 0.144936  , 0.10866758,\n",
       "       0.06636078, 0.11429058, 0.17242731, 0.22488009, 0.21771859,\n",
       "       0.1926805 , 0.17163872, 0.18028363, 0.25075281, 0.28388824,\n",
       "       0.19718044, 0.20621392, 0.25254926, 0.18663087, 0.11724649,\n",
       "       0.13574394, 0.1544653 , 0.15133641, 0.09365883, 0.0697755 ,\n",
       "       0.13277057, 0.1930563 , 0.22672081, 0.21919553, 0.18647057,\n",
       "       0.16604537, 0.20321127, 0.25263062, 0.26662944, 0.20409427,\n",
       "       0.23152517, 0.23783221, 0.16647735, 0.12955796, 0.15309097,\n",
       "       0.16537479, 0.12717009, 0.07706548, 0.0804377 , 0.13875687,\n",
       "       0.19027968, 0.20572229, 0.19840412, 0.18776075, 0.18293463,\n",
       "       0.21187392, 0.2673185 , 0.25220097, 0.1945614 , 0.21114751,\n",
       "       0.18163843, 0.13819725, 0.1403509 , 0.16901954, 0.15023383,\n",
       "       0.10675447, 0.07209627, 0.08641584, 0.13283998, 0.18486187,\n",
       "       0.18801376, 0.18513874, 0.19526641, 0.20051341, 0.21186246,\n",
       "       0.25162109, 0.20430431, 0.16116114, 0.1540692 , 0.12249308,\n",
       "       0.12742896, 0.16606795, 0.17726935, 0.14221677, 0.10731025,\n",
       "       0.05572851, 0.03400372, 0.09507492, 0.14760995, 0.18681934,\n",
       "       0.19149187, 0.20000704, 0.21409732, 0.21034924, 0.20665079,\n",
       "       0.1961162 , 0.14984484, 0.10678027, 0.09875825, 0.10833122,\n",
       "       0.15735188, 0.19255554, 0.17474566, 0.13190315, 0.08181331,\n",
       "       0.05306837, 0.05300974, 0.11160403, 0.16295792, 0.20383272,\n",
       "       0.2154547 , 0.21959598, 0.2241253 , 0.20641577, 0.17563095,\n",
       "       0.1449323 , 0.0868227 , 0.07153358, 0.08415095, 0.13170498,\n",
       "       0.18557205, 0.19042451, 0.15063537, 0.11375894, 0.08119775,\n",
       "       0.0534344 , 0.05745796, 0.1089514 , 0.16176491, 0.2200724 ,\n",
       "       0.23928349, 0.23380557, 0.21352155, 0.17670114, 0.13796446,\n",
       "       0.09873787, 0.07365273, 0.06704826, 0.10181769, 0.1442013 ,\n",
       "       0.15522493, 0.14709471, 0.11179721, 0.0841662 , 0.06621921,\n",
       "       0.08931197, 0.14773996, 0.20308022, 0.2298225 , 0.23724935,\n",
       "       0.20038324, 0.13903452, 0.09128697, 0.07647767, 0.07101896,\n",
       "       0.08492345, 0.1068528 , 0.11896177, 0.11303192, 0.09350991,\n",
       "       0.07193235, 0.05314487, 0.0506604 , 0.05919377, 0.09907932,\n",
       "       0.14740075, 0.1875061 , 0.19299441, 0.18769457, 0.15682333,\n",
       "       0.13059134, 0.11944675, 0.11590045, 0.10521106, 0.10061382,\n",
       "       0.09205534, 0.07594219, 0.05703363, 0.04488052, 0.03850754,\n",
       "       0.05452791, 0.07387198, 0.10712317, 0.13177524, 0.16238112,\n",
       "       0.1767166 , 0.18532944, 0.18474267, 0.14882741, 0.11531365,\n",
       "       0.09579042, 0.07975008, 0.05310338, 0.03362056, 0.02053322,\n",
       "       0.02403874, 0.04038457, 0.06497946, 0.08006542, 0.10549198,\n",
       "       0.11650283, 0.11905791, 0.10027046, 0.09204127, 0.07339097,\n",
       "       0.05754654, 0.04623214, 0.03014917, 0.06248433, 0.09031551,\n",
       "       0.10352244, 0.11785734, 0.10653549, 0.10114203, 0.08497264,\n",
       "       0.07185925, 0.06585539])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "result = MIC(X_fsvar,y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = result.shape[0] - sum(result <= 0)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388098166696807"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fsmic = SelectKBest(MIC, k=k).fit_transform(X_fsvar, y)\n",
    "cross_val_score(RandomForestClassifier(n_estimators=10,random_state=0),X_fsmic,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌入法\n",
    "嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。在使用嵌入法时，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小选择特征。这些权值系 数往往代表了特征对于模型的某种贡献或某种重要性，比如决策树和树的集成模型中的feature_importances_属性，可以列出各个特征对树的建立的贡献，我们就可以基于这种贡献的评估，找出对模型建立最有用的特征。因此相比于过滤法，嵌入法的结果会更加精确到模型的效用本身，对于提高模型效力有更好的效果。并且，由于考虑特征对模型的贡献，因此无关的特征(需要相关性过滤的特征)和无区分度的特征(需要方差过滤的特征)都会因为缺乏对模型的贡献而被删除。\n",
    "\n",
    "#### 嵌入法的缺点\n",
    "- 过滤法中使用的统计量可以使用统计知识和常识来查找范围(如p值应当低于显著性水平0.05)，而嵌入法中使用的权值系数却没有这样的范围可找——权值系数为0的特征对模型丝毫没有作用，但当大量特征都对模型有贡献且贡献不一时，就很难去界定一个有效的临界值。这种情况下，模型权值系数就是超参数，需要进行调参\n",
    "- 嵌入法引入了算法来挑选特征，因此其计算速度也会和应用的算法有很大的关系。如果采用计算量很大，计算缓慢的算法，嵌入法本身也会非常耗时耗力。\n",
    "\n",
    "#### sklearn中的嵌入法\n",
    "feature_selection.SelectFromModel class sklearn.feature_selection.SelectFromModel (estimator, threshold=None, prefit=False, norm_order=1, max_features=None)\n",
    "\n",
    "SelectFromModel是一个元变换器，可以与任何在拟合后具有coef_，feature_importances_属性或参数中可选惩罚项的评估器一起使用(比如随机森林和树模型就具有属性feature_importances_，逻辑回归就带有l1和l2惩罚项，线性支持向量机也支持l2惩罚项)。\n",
    "\n",
    "对于有feature_importances_的模型来说，若重要性低于提供的阈值参数，则认为这些特征不重要并被移除。 feature_importances_的取值范围是[0,1]，如果设置阈值很小，比如0.001，就可以删除那些对标签预测完全没贡 献的特征。如果设置得很接近1，可能删除大量的有效特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 47)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "RFC_ = RandomForestClassifier(n_estimators =10,random_state=0)\n",
    "X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xt8XHWd//HXJ5N7c2nSJr2mSUpT\nINxaSMNV5OoW1BbBC1UWu6uL/KSg4rrA+hNXdn3ooj9w9yeuW9GVi1rKRUCs4A8tClKgaYGWtpRe\n6CVtaUIvaXrJ/fP7Y6Z1SEMzTWZ6Zibv5+ORR885852TNyF5z5lzzpxj7o6IiKSXjKADiIhI/Knc\nRUTSkMpdRCQNqdxFRNKQyl1EJA2p3EVE0pDKXUQkDancRUTSkMpdRCQNZQb1jUeOHOlVVVVBfXsR\nkZS0ZMmSd929rL9xgZV7VVUVDQ0NQX17EZGUZGYbYxmn3TIiImlI5S4ikoZU7iIiaUjlLiKShlTu\nIiJpSOUuIpKGVO4iImkosPPcB6Oru4eO7h7aOnto7+qmvbOH9q7IdFdPZL77r8uiH+/socehOC+T\n4vwshudlU5yfRXFeFsPzwv9mhvSaJyKpLeXK/b+eW8e/P/1mQr9HYU4mRXlZDM8PfxXnZVGclx2e\njywvHZZD6bBsRgzLprQgm8KcTMwsoblERGKVcuU+raqEmy+dTE5mRvgrKxSZjvyb9T7TUWMN2NPW\nxe79HbQc6GT3gU5a9ndG5rvYfaCDlv2dhx57p6WVlgPh+c7uvm8onh3KoHRYdrjwC7L/Oj0smxEF\nUS8Eka+87BDZoQy9IIhIQqRcuddVlVJXVTro9Rws2aPh7uzv6GbX/g527utgx74Odu796/SOve2H\npjfu2M/OfR3sbe963/VlGORlhcjLDpGbFXrPdH52ZD4rRG7UdF52+LHSYdmMPPiiUZBNaX62dieJ\nyCEpV+5BMjOG5WQyLCeT8SX5MT2nrbObnfuiXgz2tbNrXycHOrtp6+zmQEc3Bzq7D5vfta+DrZHl\nBzp6aOvsZn9HFz19v3EAoCQ/69C7hJEF2YwYlsOIgr++ezj478iCbIrzsvSuQSSNqdwTLDcrxNjh\neYwdnjfodbk7nd3O3vau8IvF3vbwO4aD03s72LGvnXf3dvDW9r3s2LuDXfs7+1xXdiiDssIcyoty\nKC/MYVRRLuWFOZQX5lJWlMOowlzKi3Iozc8mI0MvAiKpRuWeQsyM7EyjNDO8S2lSeUG/z+nq7mHn\nwd1Iezt4d2+4/Jta22je005Tazvrm/fx0vqdtBw4/IUgM8PCLwKFOZRFCn/c8DzqKkuYMmE4OZmh\nRPynisggqdzTXGYog/LCXMoLc/sd29bZTXNrO02tbTTtaWf7njaaWsMvANv3tNG4az9LN+1i574O\nAHKzMqirLOXs40Zw9nEjOHVcsfb7iySJmMrdzKYD/wGEgHvd/bu9Hq8EfgaUATuBa9y9Mc5ZJcFy\ns0JUlOZTUXrk4wkt+zt5+e0dLFq/g0XrdvC9Z1YDMCw7RH11uOzPOW4kJ44pIqRdOiKBMPcjHKED\nzCwEvAVcCjQCi4FZ7r4yaszDwFPufp+ZXQT8nbv/7ZHWW1dX57pZR3rYsbedl9bvZNH6d3lx3Q7W\nN+8DoCg3k7MmjjhU9pNHFeggrsggmdkSd6/rb1wsW+71wFp3Xx9Z8TxgJrAyakwt8JXI9ELg8aOL\nK6lsREEOHz51DB8+dQwA2/e0sWhdeKt+0fod/H7l9vC4YdmcNXEEZ00s5YQxRdSUFzA8/+hORxWR\n2MRS7uOAzVHzjcCZvca8DlxFeNfNx4BCMxvh7jviklJSyqiiXK6YOo4rpo4DoHHX/kNl/+K6Hfx2\n+bZDY8sKc6gpL6CmvIBJowoPTY8oyAkqvkhaiKXc+3of3Xtfzj8CPzSz2cCfgS3AYZ/eMbPrgOsA\nJkyYcFRBJXWNL8nnE3X5fKKuAndny+4DrGnay5rtrazZvpc1TXt5dOmW93zgq3RYdrjoRxVQU14Y\nKf8CygpytGtHJAaxlHsjUBE1Px7YGj3A3bcCVwKYWQFwlbu39F6Ru88F5kJ4n/sAM0sKMzPGl+Qz\nviSfC48vP7Tc3dnW0nao9Nc2hUv/ide20tr219Ifnp9F7ZgivvqhyZxROfhPKoukq1jKfTFQY2bV\nhLfIrwY+HT3AzEYCO929B7iN8JkzIjEzs0Mf9vrg5LJDy92dptb2yBZ+K2ua9rLwzSY+/uNFzD6n\niq/9zfHkZ+uMXpHe+v2rcPcuM5sDPEP4VMifufsKM7sDaHD3J4ELgO+YmRPeLXNDAjPLEGJmjCrK\nZVRRLufVjARgb3sXdz79Jv/zlw08u2o7373yVM6dNDLgpCLJpd9TIRNFp0LKYL28fge3PLqMDTv2\nM6u+gtsuP5Gi3KygY4kkVKynQurjhJKyzpw4gqe/fD5fOH8iDy3ezIfu+jN/WLU96FgiSUHlLikt\nNyvEbZefyGNfPJeivEw+d18DX573Krsil0gQGapU7pIWplQM5zc3nsdNF9fw1LJtXHr3n/jtsm0E\ntdtRJGgqd0kbOZkhbr50Mk/OOY8xxXnc8MulXP/gEppa24KOJnLMqdwl7dSOLeLXXzyHW6afwMLV\nzVx61595dEmjtuJlSFG5S1rKDGXwvy44jt996QNMKi/gqw+/zuz/WcyW3QeCjiZyTKjcJa0dV1bA\n/C+czTc/Wssrb+/kQ3f9iQde2khXd0/Q0UQSSuUuaS+UYfzdudX8/ivnM2XCcL7x+Bt88HvP8dMX\n3j7iDcxFUpk+xCRDirvz/1Zu597n3+aVDTspzM3k02dO4O/OqWZ0cf93qxIJWqwfYlK5y5D12ubd\n/OT59fxu+TYyzJhx2lg+/4GJ1I4tCjqayPtSuYvEaPPO/fz0hbeZ37CZ/R3dfKBmJJ//wETOrxmp\nywtL0lG5ixyllv2d/OKVjfz8Lxtoam3nhNGFfO68amZMGUtOZijoeCKAyl1kwDq6enjy9a385M/r\nWb29lfLCHGafW8Vn6ispzteFySRYKneRQXJ3/rzmXe59fj3Pr3mX/OwQn6yr4HPnVVNRmh90PBmi\nVO4icbRy6x7ufWE9T74WvgnZA587k7OPGxFwKhmKdMlfkTiqHVvEXZ+cwgu3XMS4kjxufWwZBzq6\ng44l8r5U7iJHYXRxLt+58hQ27tjP3c++FXQckfcVU7mb2XQzW21ma83s1j4en2BmC83sVTNbZmaX\nxz+qSHI457iRzKqfwL3Pr+f1zbuDjiPSp37L3cxCwD3AZUAtMMvMansN+9/AfHefSvgG2j+Kd1CR\nZHLb5SdQVpjDLY8uo6NL16mR5BPLlns9sNbd17t7BzAPmNlrjAMHP9ZXDGyNX0SR5FOUm8W3rziF\nN99p5cd/Whd0HJHDxFLu44DNUfONkWXR/gW4xswagQXAjXFJJ5LELqkdxUdPG8sP/7iWNdtbg44j\n8h6xlHtfn7/uff7kLODn7j4euBx4wMwOW7eZXWdmDWbW0NzcfPRpRZLMNz9ay7CcELc8uozuHt0M\nRJJHLOXeCFREzY/n8N0unwPmA7j7IiAXGNl7Re4+193r3L2urKxsYIlFksjIghy++dGTWLppN/cv\n2hB0HJFDYin3xUCNmVWbWTbhA6ZP9hqzCbgYwMxOJFzu2jSXIWHmlLFceHwZdz69ms079wcdRwSI\nodzdvQuYAzwDrCJ8VswKM7vDzGZEhn0V+Aczex34FTDbdcNKGSLMjG9/7BQyDP7518t1r1ZJCpmx\nDHL3BYQPlEYvuz1qeiVwbnyjiaSOscPzuPXyE/nG42/wyJJGPlFX0f+TRBJIn1AViZPP1E+gvqqU\nf31qJU2tbUHHkSFO5S4SJxkZxneuOoW2rh6++cSKoOPIEKdyF4mj48oK+PIlNfzujXf43fJtQceR\nIUzlLhJn//CBiZw0tohvPLGClv2dQceRIUrlLhJnWaEM/v2qU9m1v4N/++3KoOPIEKVyF0mAk8cV\n84XzJ/LwkkaeX6OPfMixp3IXSZCbLq5h4shh3PbYcva1dwUdR4YYlbtIguRmhfj3j59K464DfP/3\nq4OOI0OMyl0kgaZVlXLt2ZX8/MUNLN20K+g4MoSo3EUS7J+mn8CYolxueWQZ7V2676ocGyp3kQQr\nyMnk21eewpqmvdyzUDf2kGND5S5yDFx4fDlXTh3HjxauZdW2PUHHkSFA5S5yjHzjI7UU52Vxy6Pa\nPSOJp3IXOUZKhmVzx8yTWdbYwofu/jNPv7FNlweWhFG5ixxDHz51DPf/fT05mRlc/+BSPjX3JZY3\ntgQdS9KQyl3kGDt/chkLbvoA/3bFyaxr2suMe17gq/NfZ/seXSZY4kflLhKAzFAG15xVycKvXcB1\n50/kN69v5YLvPcd/PLuGAx3aHy+Dp3IXCVBRbha3XXYiz978QS48oYy7n32LC7//HI8tbaSnR/vj\nZeBiKnczm25mq81srZnd2sfjd5vZa5Gvt8xsd/yjiqSvCSPy+dFnzuDh68+mvCiHm+e/zhU/+guL\nN+wMOpqkKOvvaL2ZhYC3gEuBRmAxMCty39S+xt8ITHX3vz/Seuvq6ryhoWFAoUXSWU+P8/hrW7jz\n6dW8s6eNy08Zza3TT2TCiPygo0kSMLMl7l7X37hYttzrgbXuvt7dO4B5wMwjjJ8F/Cq2mCLSW0aG\nceXp41n4jxfwlUsms/DNZi656098Z8Eq9rTp5h8Sm8wYxowDNkfNNwJn9jXQzCqBauCP7/P4dcB1\nABMmTDiqoCJDTV52iC9dUsOnplXw/d+vZu7z63lkSSNzLppE9chhA15vdiiDuqpSsjN1yC2dxVLu\n1sey99uXczXwiLv3ebjf3ecCcyG8WyamhCJD3OjiXL7/idOYfU4Vdzy1km/9ZvB3dxpfksecCydx\n1RnjyQqp5NNRLOXeCFREzY8Htr7P2KuBGwYbSkQOd/K4Yh667izefKeVA50DP12yaU8b//XcOm59\nbDk/XLhWJZ+mYjmgmkn4gOrFwBbCB1Q/7e4reo07HngGqPYYPlOtA6oiwXF3nlvdzN3PvsWyxhbG\nl+Rx40WTuPJ0lXyyi9sBVXfvAuYQLu5VwHx3X2Fmd5jZjKihs4B5sRS7iATLzLjwhHKeuOFcfja7\njtJh2dzy6HIu+j/PMX/xZjq7e4KOKIPU75Z7omjLXSR5uDt/fLOJHzy7huVbWqgozePGC2v42Onj\ntCWfZGLdcle5i8ghvUt+Qmk+cy6axMemquSThcpdRAbM3fnDqiZ+8Ie3eGPLHipH5DPnwnDJZ6rk\nA6VyF5FBc3eeXdXED559ixVbwyV/40U1XHX6OMz6OktaEi3Wco/lVEgRGaLMjEtrR3HJieWHSv4f\nH36dDIMrTx8fdDw5Ar2/EpF+HSz538w5j5ryAn72l7d1F6kkp3IXkZhlZBjXnlPFG1v2sHSTLv6a\nzFTuInJUrpw6jsKcTO5ftCHoKHIEKncROSrDcjL5eN14FizfRlOrbg2YrFTuInLU/vasSjq7nV+9\nvLn/wRIIlbuIHLWJZQV8cHIZv3h5Ix1dulRBMlK5i8iAfPacSppa23lmxTtBR5E+qNxFZEAumFzO\nhNJ87ntxQ9BRpA8qdxEZkIwM49qzK2nYuIs3trQEHUd6UbmLyIB94owK8rJCOi0yCancRWTAivOz\nuGLqOJ54bSu79nUEHUeiqNxFZFA+e04l7V09PNSg0yKTicpdRAblhNFFnFldygOLNtLdo+vNJIuY\nyt3MppvZajNba2a3vs+YT5rZSjNbYWa/jG9MEUlms8+pYsvuA/xh1fago0hEv+VuZiHgHuAyoBaY\nZWa1vcbUALcB57r7ScCXE5BVRJLUpbWjGFOcy/2LNgYdRSJi2XKvB9a6+3p37wDmATN7jfkH4B53\n3wXg7k3xjSkiySwzlME1Z1Xywtp3WdvUGnQcIbZyHwdEHylpjCyLNhmYbGZ/MbOXzGx6vAKKSGr4\n1LQKskMZ2npPErGUe1/30up91CQTqAEuAGYB95rZ8MNWZHadmTWYWUNzc/PRZhWRJDayIIePnDaG\nR5c00trWGXScIS+Wcm8EKqLmxwNb+xjzhLt3uvvbwGrCZf8e7j7X3evcva6srGygmUUkSX327Cr2\ndXTz6JLGoKMMebGU+2KgxsyqzSwbuBp4steYx4ELAcxsJOHdNOvjGVREkt9pFcOZUjGc+xdtpEen\nRQaq33J39y5gDvAMsAqY7+4rzOwOM5sRGfYMsMPMVgILga+5+45EhRaR5PXZcypZ/+4+Xlj7btBR\nhjQL6ia3dXV13tDQEMj3FpHEae/q5tzv/pHTxg/np7OnBR0n7ZjZEnev62+cPqEqInGVkxliVv0E\n/ri6iU079gcdZ8hSuYtI3H3mzEoyzHjgpQ1BRxmyVO4iEneji3OZftJoHlq8mQMd3UHHGZJU7iKS\nEJ89p4o9bV08/tqWoKMMSSp3EUmIaVUlnDC6kPte3EBQJ24MZSp3EUkIM2P2OVW8+U4rr7y9M+g4\nQ47KXUQSZuaUcRTnZel6MwFQuYtIwuRlh/jUtAqeXvEO21oOBB1nSFG5i0hCXXNmJT3u/PLlTUFH\nGVJU7iKSUBNG5HPxCeX86pVNtHfptMhjReUuIgl37dlVvLu3gwXLtwUdZchQuYtIwp03aSQTy4bx\n8xd1YPVYUbmLSMJlZBjXnlXJ65t389rm3UHHGRJU7iJyTFx1xniGZYe4/8UNQUcZElTuInJMFOZm\ncdUZ43lq2Tbe3dsedJy0p3IXkWPmM2dW0tHdw+9XbA86StpTuYvIMTN5VAEjC7Jp2KDLESRaTOVu\nZtPNbLWZrTWzW/t4fLaZNZvZa5Gvz8c/qoikOjNjWlUpr6jcE67fcjezEHAPcBlQC8wys9o+hj7k\n7lMiX/fGOaeIpIm6qlIadx3Q5QgSLJYt93pgrbuvd/cOYB4wM7GxRCRd1VeVArB4w66Ak6S3WMp9\nHLA5ar4xsqy3q8xsmZk9YmYVcUknImnnxDGFDMsOsViXAU6oWMrd+ljW+8r7vwGq3P1U4Fngvj5X\nZHadmTWYWUNzc/PRJRWRtJAZyuD0yhIWa797QsVS7o1A9Jb4eGBr9AB33+HuB09c/QlwRl8rcve5\n7l7n7nVlZWUDySsiaWBaVSmrt7fScqAz6ChpK5ZyXwzUmFm1mWUDVwNPRg8wszFRszOAVfGLKCLp\npq6qBHdYulH73ROl33J39y5gDvAM4dKe7+4rzOwOM5sRGXaTma0ws9eBm4DZiQosIqlvakUJmRmm\nUyITKDOWQe6+AFjQa9ntUdO3AbfFN5qIpKu87BAnjyvWQdUE0idURSQQ9dWlLGtsoa1TN/BIBJW7\niARiWlUpHd09LGtsCTpKWlK5i0gg6ipLAHRKZIKo3EUkECXDsqkpL1C5J4jKXUQCU1dVypINu+ju\n6f25SBkslbuIBKa+uoTW9i5Wv9MadJS0o3IXkcBMO3QRMe2aiTeVu4gEZtzwPMYU56rcE0DlLiKB\nOXjzjsUbduKu/e7xpHIXkUBNqyph+552Nu/UzTviSeUuIoGaVq397omgcheRQE0uL6QoN1PlHmcq\ndxEJVEaGURfZ7y7xo3IXkcBNqyplXfM+duxt73+wxETlLiKBq68+eJ0Z3bwjXlTuIhK4k8cVk52Z\nQYN2zcSNyl1EApeTGWJKxXDtd48jlbuIJIVpVSW8sXUP+zu6go6SFmIqdzObbmarzWytmd16hHEf\nNzM3s7r4RRSRoWBaVSndPc6rm3YHHSUt9FvuZhYC7gEuA2qBWWZW28e4QsI3x3453iFFJP2dUVlC\nhsEruq9qXMSy5V4PrHX39e7eAcwDZvYx7l+BO4G2OOYTkSGiMDeLE0YX0bBR5R4PsZT7OGBz1Hxj\nZNkhZjYVqHD3p+KYTUSGmPrqUpZu3E1nd0/QUVJeLOVufSw7dPk2M8sA7ga+2u+KzK4zswYza2hu\nbo49pYgMCXVVJRzo7Gbl1j1BR0l5sZR7I1ARNT8e2Bo1XwicDDxnZhuAs4An+zqo6u5z3b3O3evK\nysoGnlpE0lK9bt4RN7GU+2KgxsyqzSwbuBp48uCD7t7i7iPdvcrdq4CXgBnu3pCQxCKStsqLcqkc\nka+DqnHQb7m7excwB3gGWAXMd/cVZnaHmc1IdEARGVrqKktp2LhLN+8YpMxYBrn7AmBBr2W3v8/Y\nCwYfS0SGqvrqEh5d2si65n1MKi8IOk7K0idURSSp1EX2u+s6M4OjcheRpDJx5DBGFmTzisp9UFTu\nIpJUzIy6St28Y7BU7iKSdOqqSti88wDvtOgD7wOlcheRpFOvm2YPmspdRJJO7Zgi8rNDOqg6CCp3\nEUk6maEMTp9Qwiu67d6AqdxFJClNqyrlzXf20HKgM+goKUnlLiJJaVpVCe6wdJO23gdC5S4iSWnq\nhBIyM4zFus7MgKjcRSQp5WWHOHlcMQ3a7z4gKncRSVrTqkp4rXE37V3dQUdJOSp3EUla06pK6ejq\nYVljS9BRUo7KXUSSVp1u3jFgKncRSVqlw7KZVF6gg6oDoHIXkaQ2rSp8846eHt2842io3EUkqU2r\nKqG1rYvV21uDjpJSYip3M5tuZqvNbK2Z3drH49eb2XIze83MXjCz2vhHFZGhaJr2uw9Iv+VuZiHg\nHuAyoBaY1Ud5/9LdT3H3KcCdwF1xTyoiQ9L4kjxGF+WyWOe7H5VYttzrgbXuvt7dO4B5wMzoAe6+\nJ2p2GKCdYyISF2bGtOpSFr+9UzfNPgqxlPs4YHPUfGNk2XuY2Q1mto7wlvtN8YknIgL1VSW8s6eN\nxl0Hgo6SMmIpd+tj2WEvn+5+j7sfB9wC/O8+V2R2nZk1mFlDc3Pz0SUVkSFL57sfvVjKvRGoiJof\nD2w9wvh5wBV9PeDuc929zt3rysrKYk8pIkPa8aMKKczNVLkfhVjKfTFQY2bVZpYNXA08GT3AzGqi\nZj8MrIlfRBEZ6jIyjLrKEh1UPQr9lru7dwFzgGeAVcB8d19hZneY2YzIsDlmtsLMXgNuBj6bsMQi\nMiRNqy5lbdNedu7rCDpKSsiMZZC7LwAW9Fp2e9T0l+KcS0TkPeoj+90bNuzkQyeNDjhN8tMnVEUk\nJZwyvpjszAztd4+Ryl1EUkJOZogp44frptkxUrmLSMqYVl3Cii0t7O/oCjpK0lO5i0jKqKsqpavH\nWbRuR9BRkp7KXURSxlnVI6gozeOff72cpta2oOMkNZW7iKSMvOwQ/31NHXsOdPHFB5fS0dUTdKSk\npXIXkZRSO7aI733iVBo27uJbv1kRdJykFdN57iIiyeQjp47ljS17+PGf1nHyuGJm1U8IOlLS0Za7\niKSkr/3N8Zw/uYzbn3iDJRt17ntvKncRSUmhDOP/Xj2VscPzuP7BpWzfowOs0VTuIpKyivOzmPu3\ndexr7+L6B5fQ3tUddKSkoXIXkZR2/OhC7vrkaby6aTe3P75Cd2uKULmLSMqbfvIY5lw4iYcaNvPg\ny5uCjpMUVO4ikha+culkLjqhnG89uYJX3tYBVpW7iKSFUIZx96emUFGazxd/sYRtLUP7fqsqdxFJ\nG8V5Wfzk2jNo6+zh+geW0NY5dA+wqtxFJK1MKg8fYH29sYWv//qNIXuAVeUuImnnQyeN5ksX1/Do\n0kbue3FD0HECEVO5m9l0M1ttZmvN7NY+Hr/ZzFaa2TIz+4OZVcY/qohI7L50cQ2XnDiKf/3tqiF5\nieB+y93MQsA9wGVALTDLzGp7DXsVqHP3U4FHgDvjHVRE5GhkZBh3f+o0qkbkc8Mvl7Jl99A6wBrL\nlns9sNbd17t7BzAPmBk9wN0Xuvv+yOxLwPj4xhQROXqFuVnMvbaOzq4evvBAw5A6wBpLuY8DNkfN\nN0aWvZ/PAb/r6wEzu87MGsysobm5OfaUIiIDdFxZAf8xawortu7htseWD5kDrLGUu/WxrM+fjpld\nA9QB3+vrcXef6+517l5XVlYWe0oRkUG46IRR3HzJZH796hZ+9pcNQcc5JmK5nnsjUBE1Px7Y2nuQ\nmV0CfB34oLu3xyeeiEh83HDhJFZs3cO3f7uSea8Ee4mCmy6u4aOnjU3o94il3BcDNWZWDWwBrgY+\nHT3AzKYC/w1Md/emuKcUERmkjAzj+588jTufzuHdvcFufxbnZSX8e/Rb7u7eZWZzgGeAEPAzd19h\nZncADe7+JOHdMAXAw2YGsMndZyQwt4jIUSvIyeSOmScHHeOYiOk2e+6+AFjQa9ntUdOXxDmXiIgM\ngj6hKiKShlTuIiJpSOUuIpKGVO4iImlI5S4ikoZU7iIiaUjlLiKShiyoi+iYWTOwcYBPHwm8G8c4\nx5ryByeVs4PyBylZsle6e78X5wqs3AfDzBrcvS7oHAOl/MFJ5eyg/EFKtezaLSMikoZU7iIiaShV\ny31u0AEGSfmDk8rZQfmDlFLZU3Kfu4iIHFmqbrmLiMgRJEW5m9l0M1ttZmvN7NY+Hs8xs4cij79s\nZlVRj90WWb7azP4m1nUma3YzqzCzhWa2ysxWmNmXEpU9EfmjHguZ2atm9lSq5Tez4Wb2iJm9Gfn/\ncHaK5f9K5HfnDTP7lZnlJlN2MxsR+R3fa2Y/7PWcM8xseeQ5/2mRG0SkQn4zyzez30Z+b1aY2XcT\nlT0m7h7oF+EbgKwDJgLZwOtAba8xXwR+HJm+GngoMl0bGZ8DVEfWE4plnUmcfQxwemRMIfBWIrIn\nKn/U824Gfgk8lUq/O5HH7gM+H5nOBoanSn7CN69/G8iLjJsPzE6y7MOA84DrgR/2es4rwNmE7938\nO+CyJPzZ95kfyAcujPq9eT5R+WP5SoYt93pgrbuvd/cOYB4ws9eYmYT/4AAeAS6OvKLPBOa5e7u7\nvw2sjawvlnUmZXZ33+buSwHcvRVYRfgPNhES8bPHzMYDHwbuTVDuhOU3syLgfOCnAO7e4e67UyV/\nZFwmkGdmmYQL57B7HgeZ3d33ufsLQFv0YDMbAxS5+yIPN+T9wBUJyJ6Q/O6+390XRqY7gKWE7zkd\niGQo93HA5qj5Rg4vs0Nj3L0LaAFGHOG5sawzHhKR/ZDI28CpwMtxzNxntvfLwMDy/wD4J6An/pH7\nztZHhsPGxJh/ItAM/E9kt9KyLb1MAAACWklEQVS9ZjYsMfHjn9/dtwDfBzYB24AWd/99kmU/0job\n+1lnvCQi/yFmNhz4KPCHQScdoGQo9772qfU+hef9xhzt8nhLRPbwk8wKgEeBL7v7ngEnPLK45zez\njwBN7r5ksOFikIiffyZwOvBf7j4V2Ack6phNIn7+JYS3OKuBscAwM7tmUCn7Npjsg1lnvCQif/hJ\n4XdMvwL+093XDyBbXCRDuTcCFVHz4zn8beShMZEfXDGw8wjPjWWd8ZCI7JhZFuFi/4W7P5aA3Idl\n652hrzEx5j8XmGFmGwi/1b3IzB5MRPgjZOhzzFH87jS6+8F3S48QLvtESET+S4C33b3Z3TuBx4Bz\nkiz7kdYZvRsjUX+378l2hO91tPkPmguscfcfxCHnwAW1sz/qIEQmsJ7wlsbBAxsn9RpzA+89sDE/\nMn0S7z2otJ7wgZJ+15nE2Y3wvsYfpOLPvtdzLyCxB1QTkp/wgbDjI9P/AnwvVfIDZwIrCO9rN8L7\njG9MpuxRj8/m8AOqi4Gz+OsB1cuT7WffT/5/I7xhlpGo3/uY/xuDDhD5gVxO+KyQdcDXI8vuAGZE\npnOBhwkfNHoFmBj13K9HnreaqCPTfa0zFbITPgrvwDLgtchXQn7BE/Wzj3r8AhJY7gn83ZkCNET+\nHzwOlKRY/m8BbwJvAA8AOUmYfQPhreC9hLeQayPL6yK51wE/JPJBy1TIT3jr3wmfBHHwb/fzifz9\nP9KXPqEqIpKGkmGfu4iIxJnKXUQkDancRUTSkMpdRCQNqdxFRNKQyl1EJA2p3EVE0pDKXUQkDf1/\nXrT7y/xG6vQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#利用学习曲线进行判断\n",
    "threshold = np.linspace(0,(RFC_.fit(X,y).feature_importances_).max(),20)\n",
    "score = []\n",
    "for i in threshold:\n",
    "    X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_embedded,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.plot(threshold,score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.939905083368037"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded = SelectFromModel(RFC_,threshold=0.00067).fit_transform(X,y)\n",
    "X_embedded.shape\n",
    "cross_val_score(RFC_,X_embedded,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 包装法\n",
    "包装法也是一个特征选择和算法训练同时进行的方法，与嵌入法十分相似，它也是依赖于算法自身的选择，比如 coef_属性或feature_importances_属性来完成特征选择。但不同的是，我们往往使用一个目标函数作为黑盒来帮 助我们选取特征，而不是自己输入某个评估指标或统计量的阈值。包装法在初始特征集上训练评估器，并且通过 coef_属性或通过feature_importances_属性获得每个特征的重要性。然后，从当前的一组特征中修剪最不重要的 特征。在修剪的集合上递归地重复该过程，直到最终到达所需数量的要选择的特征。区别于过滤法和嵌入法的一次 训练解决所有问题，包装法要使用特征子集进行多次训练，因此它所需要的计算成本是最高的。\n",
    "\n",
    "最典型的目标函数是递归特征消除法(Recursive feature elimination, 简写为RFE)。它是一种贪婪的优化算法， 旨在找到性能最佳的特征子集。它反复创建模型，并在每次迭代时保留最佳特征或剔除最差特征，下一次迭代时，它会使用上一次建模中没有被选中的特征来构建下一个模型，直到所有特征都耗尽为止。 然后，它根据自己保留或 剔除特征的顺序来对特征进行排名，最终选出一个最佳子集。包装法的效果是所有特征选择方法中最利于提升模型表现的，它可以使用很少的特征达到很优秀的效果。除此之外，在特征数目相同时，包装法和嵌入法的效果能够匹敌，不过它比嵌入法算得更见缓慢，所以也不适用于太大型的数据。相比之下，包装法是最能保证模型效果的特征选择方法。\n",
    "\n",
    "class sklearn.feature_selection.RFE (estimator, n_features_to_select=None, step=1, verbose=0)\n",
    "\n",
    "参数estimator是需要填写的实例化后的评估器，n_features_to_select是想要选择的特征个数，step表示每次迭代中希望移除的特征个数。\n",
    "\n",
    "除此之外，RFE类有两个很重要的属性，.support_:返回所有的特征的是否最后被选 中的布尔矩阵，以及.ranking_返回特征的按数次迭代中综合重要性的排名。\n",
    "\n",
    "类feature_selection.RFECV会在交叉 验证循环中执行RFE以找到最佳数量的特征，增加参数cv，其他用法都和RFE一模一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "RFC_ = RandomForestClassifier(n_estimators =10,random_state=0)\n",
    "selector = RFE(RFC_, n_features_to_select=340, step=50).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  8,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  6,  6,\n",
       "        5,  6,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  6,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  6,  6,  5,  4,\n",
       "        4,  5,  3,  4,  4,  4,  5,  4,  5,  7,  6,  7,  7,  7,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  6,  7,  4,  3,  1,  2,  3,  3,  1,  1,  1,  1,\n",
       "        1,  3,  3,  4,  5,  5,  5,  8,  8,  9,  9,  9,  9,  8,  9,  9,  4,\n",
       "        4,  3,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  3,  3,  4,\n",
       "        5,  5,  9,  9, 10, 10, 10, 10,  7,  4,  4,  3,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  3,  3,  5,  8, 10, 10, 10,\n",
       "       10,  9,  4,  4,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  3,  4, 10, 10, 10, 10,  9,  7,  4,  3,  2,  2,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        4,  4, 10,  9, 10,  6,  6,  4,  2,  3,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  5,  9, 10,  8,  7,\n",
       "        4,  5,  3,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  2,  1,  2,  4, 10, 10, 10,  9,  7,  5,  3,  3,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  3,  5,\n",
       "        5,  9,  9,  9,  7,  5,  5,  3,  2,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  2,  4,  5,  9,  9,  9,  9,  9,  5,\n",
       "        4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  4,  5,  7, 10, 10,  9, 10,  9,  4,  1,  2,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  5, 10,\n",
       "        9, 10, 10,  9,  7,  4,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  2,  2,  4,  8,  9, 10, 10, 10,  5,  4,\n",
       "        2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  2,  3,  5, 10, 10, 10, 10,  9,  5,  4,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  3,  4,  5,  9,\n",
       "       10, 10, 10,  5,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  3,  3,  4,  8,  8, 10, 10,  9,  5,  3,  3,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        3,  3,  4, 10, 10, 10, 10,  8,  4,  3,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  4,  5,  8, 10, 10,\n",
       "       10, 10,  5,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  2,  4,  7, 10, 10, 10, 10,  8,  5,  3,  2,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  3,  3,\n",
       "        5,  5,  7,  9,  9,  9,  9,  5,  5,  2,  2,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  2,  2,  2,  3,  4,  5,  5,  8,  9,  9,  9,\n",
       "        9,  7,  4,  4,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        3,  3,  3,  5,  5,  9,  8,  9,  9,  9,  9,  9,  5,  4,  4,  2,  2,\n",
       "        1,  1,  1,  1,  1,  2,  1,  1,  1,  1,  2,  2,  3,  4,  5,  5,  9,\n",
       "        8,  8,  8,  8,  8,  8,  7,  8,  6,  4,  2,  2,  1,  1,  2,  2,  1,\n",
       "        2,  2,  3,  2,  2,  4,  4,  5,  5,  8,  8,  8,  7,  7,  7,  7,  7,\n",
       "        7,  7,  5,  5,  4,  5,  4,  3,  3,  3,  4,  3,  3,  4,  3,  4,  5,\n",
       "        5,  6,  7,  7,  7,  6,  7,  8,  8,  8,  9,  9,  9,  9,  6,  8,  8,\n",
       "        8,  7,  8,  8,  8,  7,  8,  8,  8,  8,  8,  7,  8,  8,  8,  8,  9,\n",
       "       10,  7])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389522459432109"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wrapper = selector.transform(X)\n",
    "cross_val_score(RFC_,X_wrapper,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAEyCAYAAACLeQv5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgIhAAAAgCHz/wOvnXfiZ9SU9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#包装法学习曲线\n",
    "score = []\n",
    "for i in range(1,751,50):\n",
    "    X_wrapper = RFE(RFC_,n_features_to_select=i, step=50).fit_transform(X,y)\n",
    "    once = cross_val_score(RFC_,X_wrapper,y,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,751,50),score)\n",
    "plt.xticks(range(1,751,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择总结\n",
    "经验来说，过滤法最快，但更粗糙。包装法和嵌入法更精确，比较适合具体到算法去调整，但计算量比较大，运行时间长。当数据量特征维度很大的时候，优先使用方差过滤和互信息法调整，再上其他特征选择方法。\n",
    "\n",
    "特征的组合可能会更加有效，称之为衍生特征。这是比调参和特征选择更难的，提升算法表现的高深方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 额外的内容。。。\n",
    "- OrdinalEncoder与LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinalEncoder = OrdinalEncoder(categories=[\n",
    "    ['1-7H','8-12H','13-18H','19-24H'],\n",
    "    ['AA','BB','CC','DD','EE','FF','GG','HH','II'],\n",
    "    ['M','F'],\n",
    "    ['iOS','Android','iPhone OS'],\n",
    "    ['元朗', '沙田', '观塘', '葵青', '屯门', '黄大仙', '北区', '西贡', '深水埗', '九龙城',\n",
    "       '东区', '大埔', '油尖旺', '南区', '荃湾', '离岛', '中西区', '湾仔'],\n",
    "    ['与父母同住', '租用', '公共房屋', '自置(无按揭)', '自置(有按揭)', '其他', '套房'],\n",
    "                                 ])\n",
    "df_.loc[:,['apply_hour','grade','gender','system','分区','房屋类别']] = ordinalEncoder.fit_transform(df_.loc[:,['apply_hour','grade','gender','system','分区','房屋类别']])\n",
    "df_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y = LabelEncoder().fit_transform(df_['是否逾期'])\n",
    "X = df_.drop(['是否逾期'],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
